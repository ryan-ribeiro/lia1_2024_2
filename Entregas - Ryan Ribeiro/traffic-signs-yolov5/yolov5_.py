# -*- coding: utf-8 -*-
"""YOLOv5 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bIveiKykrLfzQ2h6rs3svp4nMHaoC-LA

# YOLOv5 Classification Tutorial

YOLOv5 supports classification tasks too. This is the official YOLOv5 classification notebook tutorial. YOLOv5 is maintained by [Ultralytics](https://github.com/ultralytics/yolov5).

This notebook covers:

*   Inference with out-of-the-box YOLOv5 classification on ImageNet
*  [Training YOLOv5 classification](https://blog.roboflow.com//train-YOLOv5-classification-custom-data) on custom data

*Looking for custom data? Explore over 66M community datasets on [Roboflow Universe](https://universe.roboflow.com).*

This notebook was created with Google Colab. [Click here](https://colab.research.google.com/drive/1FiSNz9f_nT8aFtDEU3iDAQKlPT8SCVni?usp=sharing) to run it.

# Setup

Pull in respective libraries to prepare the notebook environment.
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5  # clone
# %cd yolov5
# %pip install -qr requirements.txt  # install

import torch
import utils
display = utils.notebook_init()  # checks

"""# 1. Infer on ImageNet

To demonstrate YOLOv5 classification, we'll leverage an already trained model. In this case, we'll download the ImageNet trained models pretrained on ImageNet using YOLOv5 Utils.
"""

from utils.downloads import attempt_download

p5 = ['n', 's', 'm', 'l', 'x']  # P5 models
cls = [f'{x}-cls' for x in p5]  # classification models

for x in cls:
    attempt_download(f'weights/yolov5{x}.pt')

"""Now, we can infer on an example image from the ImageNet dataset."""

#Download example image
import requests
image_url = "https://i.imgur.com/OczPfaz.jpg"
img_data = requests.get(image_url).content
with open('bananas.jpg', 'wb') as handler:
    handler.write(img_data)

#Infer using classify/predict.py
!python classify/predict.py --weights ./weigths/yolov5s-cls.pt --source bananas.jpg

"""From the output, we can see the ImageNet trained model correctly predicts the class `banana` with `0.95` confidence.

## 2. (Optional) Validate

Use the `classify/val.py` script to run validation for the model. This will show us the model's performance on each class.

First, we need to download ImageNet.
"""

# # WARNING: takes ~20 minutes
# !bash data/scripts/get_imagenet.sh --val

# # run the validation script
# !python classify/val.py --weights ./weigths/yolov5s-cls.pt --data ../datasets/imagenet

"""The output shows accuracy metrics for the ImageNet validation dataset including per class accuracy.

# 3. Train On Custom Data

To train on custom data, we need to prepare a dataset with custom labels.

To prepare custom data, we'll use [Roboflow](https://roboflow.com). Roboflow enables easy dataset prep with your team, including labeling, formatting into the right export format, deploying, and active learning with a `pip` package.

If you need custom data, there are over 66M open source images from the community on [Roboflow Universe](https://universe.roboflow.com).

(For more guidance, here's a detailed blog on [training YOLOv5 classification on custom data](https://blog.roboflow.com/train-YOLOv5-classification-custom-data).)


Create a free Roboflow account, upload your data, and label.

![](https://s4.gifyu.com/images/fruit-labeling.gif)

### Load Custom Dataset

Next, we'll export our dataset into the right directory structure for training YOLOv5 classification to load into this notebook. Select the `Export` button at the top of the version page, `Folder Structure` type, and `show download code`.

The ensures all our directories are in the right format:

```
dataset
â”œâ”€â”€ train
â”‚Â Â  â”œâ”€â”€ class-one
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ IMG_123.jpg
â”‚Â Â  â””â”€â”€ class-two
â”‚Â Â      â”œâ”€â”€ IMG_456.jpg
â”œâ”€â”€ valid
â”‚Â Â  â”œâ”€â”€ class-one
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ IMG_789.jpg
â”‚Â Â  â””â”€â”€ class-two
â”‚Â Â      â”œâ”€â”€ IMG_101.jpg
â”œâ”€â”€ test
â”‚Â Â  â”œâ”€â”€ class-one
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ IMG_121.jpg
â”‚Â Â  â””â”€â”€ class-two
â”‚Â Â      â”œâ”€â”€ IMG_341.jpg
```

![](https://i.imgur.com/BF9BNR8.gif)


Copy and paste that snippet into the cell below.
"""

# Commented out IPython magic to ensure Python compatibility.
# Ensure we're in the right directory to download our custom dataset
import os
os.makedirs("../datasets/", exist_ok=True)
# %cd ../datasets/

# REPLACE the below with your exported code snippet from above
!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="Jbx8FKHjs8dAPgHYtV7X")
project = rf.workspace("hautique-x").project("traffic-signs-detection-txg3k")
version = project.version(1)
dataset = version.download("folder")

#Save the dataset name to the environment so we can use it in a system call later
dataset_name = dataset.location.split(os.sep)[-1]
os.environ["DATASET_NAME"] = dataset_name

"""### Train On Custom Data ðŸŽ‰
Here, we use the DATASET_NAME environment variable to pass our dataset to the `--data` parameter.

Note: we're training for 100 epochs here. We're also starting training from the pretrained weights. Larger datasets will likely benefit from longer training.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ../yolov5
!python classify/train.py --model yolov5s-cls.pt --data $DATASET_NAME --epochs 100 --img 128 --pretrained weights/yolov5s-cls.pt

"""### Validate Your Custom Model

Repeat step 2 from above to test and validate your custom model.
"""

!python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data ../datasets/$DATASET_NAME

"""### Infer With Your Custom Model"""

#Get the path of an image from the test or validation set
if os.path.exists(os.path.join(dataset.location, "test")):
  split_path = os.path.join(dataset.location, "test")
else:
  os.path.join(dataset.location, "valid")
example_class = os.listdir(split_path)[0]
example_image_name = os.listdir(os.path.join(split_path, example_class))[0]
example_image_path = os.path.join(split_path, example_class, example_image_name)
os.environ["/content/e10f94_096caabe7135431bbe50f781d504626c~mv2.jpg"] = example_image_path

print(f"Inferring on an example of the class '{example_class}'")

#Infer
!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source $TEST_IMAGE_PATH

"""We can see the inference results show ~3ms inference and the respective classes predicted probabilities.

## (OPTIONAL) Improve Our Model with Active Learning

Now that we've trained our model once, we will want to continue to improve its performance. Improvement is largely dependent on improving our dataset.

We can programmatically upload example failure images back to our custom dataset based on conditions (like seeing an underrpresented class or a low confidence score) using the same `pip` package.
"""

# # Upload example image
# project.upload(image_path)

# # Example upload code
# min_conf = float("inf")
# for pred in results:
#     if pred["score"] < min_conf:
#         min_conf = pred["score"]
# if min_conf < 0.4:
#     project.upload(image_path)

"""# (BONUS) YOLOv5 classify/predict.py Accepts Several Input Methods
- Webcam: `python classify/predict.py --weights yolov5s-cls.pt --source 0`
- Image `python classify/predict.py --weights yolov5s-cls.pt --source img.jpg`
- Video: `python classify/predict.py --weights yolov5s-cls.pt --source vid.mp4`
- Directory: `python classify/predict.py --weights yolov5s-cls.pt --source path/`
- Glob: `python classify/predict.py --weights yolov5s-cls.pt --source 'path/*.jpg'`
- YouTube: `python classify/predict.py --weights yolov5s-cls.pt --source 'https://youtu.be/Zgi9g1ksQHc'`
- RTSP, RTMP, HTTP stream: `python classify/predict.py --weights yolov5s-cls.pt --source 'rtsp://example.com/media.mp4'`

###Directory Example
"""

#Directory infer
# os.environ["TEST_CLASS_PATH"] = test_class_path = os.path.join(*os.environ["TEST_IMAGE_PATH"].split(os.sep)[:-1])
# print(f"Infering on all images from the directory {os.environ['TEST_CLASS_PATH']}")
# !python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source /$TEST_CLASS_PATH/

"""###YouTube Example"""

#YouTube infer
!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source 'https://www.youtube.com/watch?v=oW6m7fABIGs&pp=ygUNdHJhZmZpYyBzaWducw%3D%3D'

"""**Testando o modelo**"""

import torch
import cv2
import numpy as np
from PIL import Image

# Caminhos para o modelo e a imagem (ajuste conforme necessÃ¡rio)
model_path = '/content/best.pt'  # Substitua pelo caminho do seu modelo
# img_path = '/content/stop-sign.jpg'      # Stop sign
# img_path = '/content/general-caution-sign.jpg'    # General caution sign
img_path = '/content/speed-limit-30kmh.jpg'        # Speed limit 30 km/h

import torch
import cv2
import numpy as np
from PIL import Image
import torch.nn.functional as F

# Carregar o modelo
model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)

# Se a GPU estiver disponÃ­vel, mover o modelo para GPU
if torch.cuda.is_available():
    model.to('cuda')

# Carregar a imagem
img = Image.open(img_path)

# Converter a imagem PIL para um array NumPy
img = np.array(img)

# Redimensionar a imagem para o tamanho esperado pelo modelo (ex.: 224x224)
img = cv2.resize(img, (224, 224))

# Converter o array NumPy para um tensor PyTorch e mudar o tipo de dado para float32
img = torch.from_numpy(img).type(torch.float32)

# Normalizar a imagem (dividir os valores de pixel por 255)
img /= 255.0

# Adicionar a dimensÃ£o do lote (batch)
img = img.permute(2, 0, 1).unsqueeze(0)

# Mover a imagem para o mesmo dispositivo do modelo (GPU, se disponÃ­vel)
if torch.cuda.is_available():
    img = img.to('cuda')

# Lista de classes de sinais de trÃ¢nsito
classes = [
    'Ahead only', 'Beware of ice-snow', 'Bicycles crossing', 'Bumpy road',
    'Children crossing', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve',
    'End of all speed and passing limits', 'End of no passing', 'End of no passing by vehicles over 3-5 metric tons',
    'End of speed limit (80km-h)', 'General caution', 'Go straight or left', 'Go straight or right',
    'Keep left', 'Keep right', 'No entry', 'No passing', 'No passing for vehicles over 3-5 metric tons',
    'No vehicles', 'Pedestrians', 'Priority road', 'Right-of-way at the next intersection', 'Road narrows on the right',
    'Road work', 'Roundabout mandatory', 'Slippery road', 'Speed limit (100km-h)', 'Speed limit (120km-h)',
    'Speed limit (20km-h)', 'Speed limit (30km-h)', 'Speed limit (50km-h)', 'Speed limit (60km-h)',
    'Speed limit (70km-h)', 'Speed limit (80km-h)', 'Stop', 'Traffic signals', 'Turn left ahead', 'Turn right ahead',
    'Vehicles over 3-5 metric tons prohibited', 'Wild animals crossing', 'Yield'
]

# Realizar a classificaÃ§Ã£o
results = model(img)

# Aplicar softmax para obter as probabilidades das classes
probabilities = F.softmax(results, dim=1)

# Obter o Ã­ndice da classe prevista
predicted_class_idx = torch.argmax(probabilities, dim=1).item()

# Obter a confianÃ§a (probabilidade) da classe prevista
confidence = probabilities[0][predicted_class_idx].item()

# Exibir o nome da classe prevista e a confianÃ§a
predicted_class_name = classes[predicted_class_idx]
print(f'PrediÃ§Ã£o de classe: {predicted_class_idx} - {predicted_class_name}')
print(f'ConfianÃ§a do modelo: {confidence * 100:.2f}%')

import torch
import torch.nn.functional as F

# Lista de classes de sinais de trÃ¢nsito
classes = [
    'Ahead only', 'Beware of ice-snow', 'Bicycles crossing', 'Bumpy road',
    'Children crossing', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve',
    'End of all speed and passing limits', 'End of no passing', 'End of no passing by vehicles over 3-5 metric tons',
    'End of speed limit (80km-h)', 'General caution', 'Go straight or left', 'Go straight or right',
    'Keep left', 'Keep right', 'No entry', 'No passing', 'No passing for vehicles over 3-5 metric tons',
    'No vehicles', 'Pedestrians', 'Priority road', 'Right-of-way at the next intersection', 'Road narrows on the right',
    'Road work', 'Roundabout mandatory', 'Slippery road', 'Speed limit (100km-h)', 'Speed limit (120km-h)',
    'Speed limit (20km-h)', 'Speed limit (30km-h)', 'Speed limit (50km-h)', 'Speed limit (60km-h)',
    'Speed limit (70km-h)', 'Speed limit (80km-h)', 'Stop', 'Traffic signals', 'Turn left ahead', 'Turn right ahead',
    'Vehicles over 3-5 metric tons prohibited', 'Wild animals crossing', 'Yield'
]

# Realizar a classificaÃ§Ã£o
results = model(img)

# Aplicar softmax para converter logits em probabilidades
probabilities = F.softmax(results, dim=1)

# Obter o Ã­ndice da classe prevista
predicted_class_idx = torch.argmax(probabilities, dim=1).item()

# Obter a confianÃ§a da classe prevista
confidence = probabilities[0][predicted_class_idx].item()

# Exibir o nome da classe correspondente e a confianÃ§a
predicted_class_name = classes[predicted_class_idx]
print(f'PrediÃ§Ã£o de classe: {predicted_class_idx} - {predicted_class_name}')
print(f'ConfianÃ§a do modelo: {confidence * 100:.2f}%')