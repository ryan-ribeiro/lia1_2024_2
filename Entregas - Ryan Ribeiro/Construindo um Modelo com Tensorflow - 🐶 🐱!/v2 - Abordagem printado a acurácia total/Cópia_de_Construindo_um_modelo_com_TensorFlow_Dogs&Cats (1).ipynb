{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu5OLDcwuSoe"
      },
      "source": [
        "# **Construindo um Modelo com Tensorflow -  🐶 🐱!**\n",
        "\n",
        "**Problema: uma imagem, dizer se é um dog ou um cat.**\n",
        "\n",
        "Computer Vision; Deep Learning; Machine Learning; Artificial Inteligence! Nada disso faz sentido sem dados, muitos dados (Big Data! 🚀). Para isso, teremos:\n",
        "\n",
        "* **Treinamento**: 25.000 imagens nomeadas: 12.500 de dogs e 12.500 de cats.\n",
        "* **Teste**: 1.000 imagens de dogs e cats.\n",
        "\n",
        "Usa-se os dados de treino para treinar o algoritmo e então criar o modelo preditivo. Usa-se os dados de teste para confirmar o desempenho do modelo preditivo já treinado, ou seja, apresenta-se ao modelo preditivo dados que ele não viu durante o treinamento, a fim de garantir que ele seja capaz de fazer previsões.\n",
        "\n",
        "Por fim, o modelo de duas camadas de convolução seguidas de pooling, a camada de flattening, e as camadas totalmente conectadas (Dense), com a função de ativação sigmoid para a saída binária.\n",
        "\n",
        "**Não há mágica. Há matemática!** 🧙"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv1N0nRuxwL-"
      },
      "source": [
        "**Fonte de dados**\n",
        "\n",
        "O Kaggle oferece diversos datasets públicos que podem ser usados para você desenvolver seus projetos e incluir no seu portfólio, uma excelente forma de demonstrar suas habilidades em Data Science e Machine Learning. Usaremos como fonte de dados, o famoso [dataset Dogs and Cats](https://www.kaggle.com/c/dogs-vs-cats/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B80jFLJAym_v"
      },
      "source": [
        "**Carregando os dados de Treino e Teste**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN2T6cv24Y6A"
      },
      "source": [
        "**Construindo a Rede Neural Convolucional**\n",
        "\n",
        "O Keras é uma biblioteca do TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LNpCfaa8NfdY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eb0TUqkQNjaI"
      },
      "outputs": [],
      "source": [
        "import keras as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XJldwmiJ4hHA"
      },
      "outputs": [],
      "source": [
        "# Importar K e suas funções necessárias\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MYZrHMd85PqQ"
      },
      "outputs": [],
      "source": [
        "# Inicializando a Rede Neural Convolucional\n",
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FrympYJ96BWg"
      },
      "outputs": [],
      "source": [
        "# Definindo a arquitetura do modelo\n",
        "classifier = Sequential()\n",
        "# Usando Input como a primeira camada\n",
        "classifier.add(Input(shape=(64, 64, 3)))  # Definindo a forma da entrada\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))  # Camada convolucional adicional\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Conv2D(128, (3, 3), activation='relu'))  # Camada convolucional adicional\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compilando o modelo\n",
        "classifier.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['binary_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1l-VgZ78NNS"
      },
      "source": [
        "**Pré-processamento**\n",
        "\n",
        "Fazer pré-processamento nos dados, em nosso caso as imagens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T8au9i8V7mDZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Criar o objeto com as regras de pré-processamento\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "BLiOSL6h7vAI",
        "outputId": "fdd4c566-a918-409a-831b-f0c3e1875be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Pré-processamento das imagens de treino\n",
        "training_set = train_datagen.flow_from_directory(r'C:\\Users\\ryanr\\Documents\\Python\\datasets\\dogs-vs-cats\\train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 64,\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=198,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ephZE1Y59LKq"
      },
      "source": [
        "**Treinamento do Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3KVRGudo9No6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryanr\\Documents\\Python\\venvs\\dogs-or-cats\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - binary_accuracy: 0.4963 - loss: 0.7069\n",
            "Epoch 2/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 880ms/step - binary_accuracy: 0.5080 - loss: 0.6926\n",
            "Epoch 3/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 665ms/step - binary_accuracy: 0.5361 - loss: 0.6893\n",
            "Epoch 4/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 698ms/step - binary_accuracy: 0.5570 - loss: 0.6858\n",
            "Epoch 5/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 484ms/step - binary_accuracy: 0.5618 - loss: 0.6828\n",
            "Epoch 6/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 221ms/step - binary_accuracy: 0.5701 - loss: 0.6751\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ryanr\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 424ms/step - binary_accuracy: 0.5790 - loss: 0.6726\n",
            "Epoch 8/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 388ms/step - binary_accuracy: 0.6066 - loss: 0.6605\n",
            "Epoch 9/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 363ms/step - binary_accuracy: 0.6004 - loss: 0.6574\n",
            "Epoch 10/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 341ms/step - binary_accuracy: 0.6111 - loss: 0.6535\n",
            "Epoch 11/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 327ms/step - binary_accuracy: 0.5904 - loss: 0.6629\n",
            "Epoch 12/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - binary_accuracy: 0.6035 - loss: 0.6494\n",
            "Epoch 13/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 315ms/step - binary_accuracy: 0.6444 - loss: 0.6324\n",
            "Epoch 14/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 303ms/step - binary_accuracy: 0.6413 - loss: 0.6357\n",
            "Epoch 15/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 329ms/step - binary_accuracy: 0.6456 - loss: 0.6323\n",
            "Epoch 16/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 328ms/step - binary_accuracy: 0.6481 - loss: 0.6202\n",
            "Epoch 17/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 292ms/step - binary_accuracy: 0.6471 - loss: 0.6149\n",
            "Epoch 18/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 150ms/step - binary_accuracy: 0.6679 - loss: 0.6032\n",
            "Epoch 19/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 334ms/step - binary_accuracy: 0.6634 - loss: 0.6042\n",
            "Epoch 20/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 290ms/step - binary_accuracy: 0.6782 - loss: 0.6062\n",
            "Epoch 21/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 367ms/step - binary_accuracy: 0.6661 - loss: 0.6155\n",
            "Epoch 22/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - binary_accuracy: 0.6762 - loss: 0.5974\n",
            "Epoch 23/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 284ms/step - binary_accuracy: 0.6666 - loss: 0.6049\n",
            "Epoch 24/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 153ms/step - binary_accuracy: 0.6705 - loss: 0.5984\n",
            "Epoch 25/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 301ms/step - binary_accuracy: 0.6928 - loss: 0.5746\n",
            "Epoch 26/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 280ms/step - binary_accuracy: 0.6838 - loss: 0.5798\n",
            "Epoch 27/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 269ms/step - binary_accuracy: 0.7027 - loss: 0.5735\n",
            "Epoch 28/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 268ms/step - binary_accuracy: 0.7058 - loss: 0.5746\n",
            "Epoch 29/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 273ms/step - binary_accuracy: 0.6986 - loss: 0.5772\n",
            "Epoch 30/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 145ms/step - binary_accuracy: 0.7090 - loss: 0.5701\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2166fce4c80>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Executando o treinamento\n",
        "classifier.fit(training_set,\n",
        "               steps_per_epoch=70,\n",
        "               epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl1MFhzd9aph"
      },
      "source": [
        "Treinamento concluído com sucesso! 💪 Observe se ao final de cada época a acurácia aumenta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OIAQ0GU-WrK"
      },
      "source": [
        "**Teste do Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ],
      "source": [
        "print(training_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testar o modelo treinado com TODAS AS IMAGENS que ele ainda não viu. Por fim, verificamos o resultado da acurácia total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12500 images belonging to 1 classes.\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step\n",
            "Confiança média do modelo: 54.58%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Avaliação do Modelo\n",
        "# Configurando o gerador de dados de teste (sem data augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    r'C:\\Users\\ryanr\\Documents\\Python\\datasets\\dogs-vs-cats\\test1',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode=None,  # Sem labels, logo, a métrica de test_loss não será calculada.\n",
        "    shuffle=True  # Para manter a ordem das imagens\n",
        ")\n",
        "\n",
        "# Obtendo as predições do modelo\n",
        "predictions = classifier.predict(test_set)\n",
        "\n",
        "# Calculando a confiança das predições\n",
        "confidence_scores = np.max(predictions, axis=1)  # Para um modelo binário, isso dá a confiança da predição\n",
        "\n",
        "# Calculando a confiança média\n",
        "mean_confidence = np.mean(confidence_scores)\n",
        "\n",
        "# Imprimindo a confiança média\n",
        "print(f'Confiança média do modelo: {mean_confidence * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Previsão: Cachorro\n",
            "Confiança do modelo para a imagem: 65.51%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Carregando e pré-processando uma única imagem\n",
        "img_path = r'C:\\Users\\ryanr\\Documents\\Python\\datasets\\dogs-vs-cats\\test1\\test1\\318.jpg'  # Coloque aqui o caminho da sua imagem\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Normalizando a imagem\n",
        "img_array /= 255.0\n",
        "\n",
        "# Fazendo a predição para a imagem\n",
        "prediction = classifier.predict(img_array)\n",
        "\n",
        "# Determinando se é um cachorro ou gato\n",
        "if prediction[0][0] >= 0.5:\n",
        "    classification = \"Cachorro\"\n",
        "else:\n",
        "    classification = \"Gato\"\n",
        "\n",
        "# Predição:\n",
        "print(\"Previsão:\", classification)\n",
        "\n",
        "# Calculando a confiança da predição\n",
        "confidence = np.max(prediction)\n",
        "\n",
        "# Imprimindo a confiança da predição\n",
        "print(f'Confiança do modelo para a imagem: {confidence * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goRr2pHz-qrp"
      },
      "source": [
        "**O modelo recebeu uma imagem que nunca tinha visto antes e com base no que aprendeu durante o treinamento, foi capaz de classificar.**\n",
        "\n",
        "Convertemos a imagem de teste em um vetor de pixels e apresentamos ao modelo.\n",
        "O modelo compara o vetor da imagem de teste com seus pesos e então emite a classificação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsCG3KP9kwr"
      },
      "source": [
        "**Melhorias adicionais para este modelo:**\n",
        "\n",
        "*   Aumentar o número de épocas para 25 para uma aprendizagem mais profunda.\n",
        "*   aumentar o redimensionamento da imagem de 64x64 para 256x256.\n",
        "*   Aumentar o tamanho do lote de 32 para 64.\n",
        "*   Alterar a arquitetura da rede incluindo mais uma camada convolucional.\n",
        "*   Avaliar outras métricas do modelo e ajustar os hiperparâmetros de acordo.\n",
        "*   Experimentar outros algoritmos de otimização.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWz1StcE-MZz"
      },
      "source": [
        "Fim! 🔥"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
